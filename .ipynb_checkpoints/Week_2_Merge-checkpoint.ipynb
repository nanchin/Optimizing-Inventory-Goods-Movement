{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "from scipy.stats import skew,kurtosis\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# to view all columns\n",
    "pd.set_option('display.max_columns',500)\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_object(arg_df):\n",
    "    \n",
    "    object_list=[]\n",
    "    category_list=[]\n",
    "    bool_list=[]\n",
    "    unilabel_list=[]\n",
    "    missing_list=[]\n",
    "    \n",
    "    for c in arg_df.columns:\n",
    "        if arg_df[c].dtypes==object:\n",
    "            object_list.append(c)\n",
    "        elif str(arg_df[c].dtypes)=='category':\n",
    "            category_list.append(c)\n",
    "        elif arg_df[c].dtypes==bool:\n",
    "            bool_list.append(c)\n",
    "    if len(object_list)+len(category_list)+len(bool_list)>0:    \n",
    "        index_list=['Count','Unique','Missing (%)','Top','Top (%)','Bottom','Bottom (%)']\n",
    "        df_summary=pd.DataFrame(data=np.zeros((len(index_list),len(object_list))),index=index_list,columns=object_list)\n",
    "\n",
    "        for col in object_list+category_list+bool_list:\n",
    "            vc=arg_df[col].value_counts().reset_index()\n",
    "            df_summary.loc['Count',col]=(arg_df[col].count())\n",
    "            df_summary.loc['Unique',col]=len(arg_df[col].unique())\n",
    "            df_summary.loc['Missing (%)',col]=arg_df[col].isna().mean()*100\n",
    "            df_summary.loc['Top',col]=vc.iloc[0,0]\n",
    "            df_summary.loc['Top (%)',col]=vc.iloc[0,1]/len(arg_df)*100\n",
    "            if len(arg_df[col].unique())>1:\n",
    "                df_summary.loc['Bottom',col]=vc.iloc[-1,0]\n",
    "                df_summary.loc['Bottom (%)',col]=vc.iloc[-1,1]/len(arg_df)*100\n",
    "            else:\n",
    "                unilabel_list.append(col)\n",
    "            if df_summary.loc['Missing (%)',col]==100:\n",
    "                missing_list.append(col)\n",
    "                \n",
    "        df_summary=df_summary.T.sort_values(['Missing (%)','Unique'],ascending=False)\n",
    "        df_summary=df_summary[(df_summary['Unique']>1) & (df_summary['Missing (%)']!=100)]\n",
    "        df_summary.reset_index(inplace=True)\n",
    "        df_summary.index=df_summary.index+1\n",
    "        df_summary.columns=['Attribute']+index_list\n",
    "        \n",
    "        print('SUMMARY OF {} NON-NUMERICAL ATTRIBUTES:\\n'.format(\n",
    "            len(object_list)+len(category_list)+len(bool_list)))\n",
    "        if len(object_list)>0:\n",
    "            print('{} Object Columns'.format(len(object_list)))\n",
    "        if len(category_list)>0:\n",
    "            print('{} Categorical Columns'.format(len(category_list)))\n",
    "        if len(bool_list)>0:\n",
    "            print('{} Bool Columns'.format(len(bool_list)))\n",
    "        if len(unilabel_list)>0:\n",
    "            print('\\n{} Columns with Single Label : \\n{}'.format(len(unilabel_list),unilabel_list))\n",
    "        if len(missing_list)>0:\n",
    "            print('\\n{} Empty Columns: \\n{}'.format(len(missing_list),missing_list))   \n",
    "            \n",
    "        del arg_df,object_list,vc,index_list,unilabel_list,missing_list\n",
    "        gc.collect()\n",
    "        return df_summary\n",
    "    else:\n",
    "        print('No Non-Numerical Attributes')\n",
    "        \n",
    "def summary_numerical(arg_df):\n",
    "\n",
    "    target_list=[]\n",
    "    missing_list=[]\n",
    "    zero_skew_list=[]\n",
    "    \n",
    "    for c in arg_df.columns:\n",
    "        datatype=arg_df[c].dtypes\n",
    "        if datatype != object and datatype != bool and str(datatype) != 'category':\n",
    "            target_list.append(c)\n",
    "    if len(target_list)>0:\n",
    "        from scipy.stats import skew,kurtosis\n",
    "        \n",
    "        index_list=['Count','Missing (%)','Mean','Median','Min','Max','Skewness','Kurtosis']\n",
    "        df_summary=pd.DataFrame(data=np.zeros((len(index_list),len(target_list))),\n",
    "                                index=index_list,columns=target_list)\n",
    "        for col in target_list:\n",
    "            df_summary.loc['Count',col]=arg_df[col].count()\n",
    "            df_summary.loc['Missing (%)',col]=arg_df[col].isna().mean()*100\n",
    "            if df_summary.loc['Missing (%)',col]!=100:\n",
    "                df_summary.loc['Mean',col]=arg_df[col].mean()\n",
    "                df_summary.loc['Median',col]=arg_df[col].median()\n",
    "                df_summary.loc['Min',col]=arg_df[col].min()\n",
    "                df_summary.loc['Max',col]=arg_df[col].max()\n",
    "                df_summary.loc['Skewness',col]=skew(arg_df[col])\n",
    "                if df_summary.loc['Skewness',col]==0:\n",
    "                    zero_skew_list.append(col)\n",
    "                df_summary.loc['Kurtosis',col]=kurtosis(arg_df[col])\n",
    "            else:\n",
    "                missing_list.append(col)\n",
    "                \n",
    "        df_summary=df_summary.T.sort_values(['Missing (%)','Skewness'],ascending=False)\n",
    "        df_summary=df_summary[(df_summary['Skewness']!=0) & (df_summary['Missing (%)']!=100)]\n",
    "        df_summary.reset_index(inplace=True)\n",
    "        df_summary.index=df_summary.index+1\n",
    "        df_summary.columns=['Attribute']+index_list\n",
    "        \n",
    "        print('SUMMARY OF {} NUMERICAL ATTRIBUTES:'.format(len(target_list)))\n",
    "        if len(zero_skew_list)>0:\n",
    "            print('\\n{} Columns with Single Value: \\n{}'.format(len(zero_skew_list),zero_skew_list))\n",
    "        if len(missing_list)>0:\n",
    "            print('\\n{} Empty Columns: \\n{}'.format(len(missing_list),missing_list))\n",
    "        del arg_df,target_list,index_list\n",
    "        gc.collect()\n",
    "\n",
    "        return df_summary\n",
    "    else:\n",
    "        print('No Numerical Attributes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath_1='C:/Users/Nan/Documents/GitHub_Data/merge.csv'\n",
    "filepath_2='C:/Users/Nan/Documents/GitHub_Data/merge_dispatch.csv'\n",
    "#filename_1=filepath_1.rstrip('.csv')\n",
    "filename_2=filepath_2.rstrip('.csv')\n",
    "#merge=pd.read_csv(filepath_1)\n",
    "merge_dispatch=pd.read_csv(filepath_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "ax=merge_dispatch.groupby('Order Number')['Pallet Number'].count().plot(kind='hist',bins=50)\n",
    "plt.title('Distribution of Total Pallet of Order Number',fontsize=20)\n",
    "ax.set_xlabel('Quantity of Order Number',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dispatch['Transaction Date Time']=pd.to_datetime(merge_dispatch['Transaction Date Time'],format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dispatch.set_index(keys='Transaction Date Time',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dispatch.groupby('Pallet Number')['New Value'].last().value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dispatch[['Transaction Date','Pallet Number']].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.pivot_table(data=merge_dispatch,index='Transaction Date',\n",
    "#               columns='Pallet Number',values='New Value',aggfunc='max',fill_value=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dispatch['Location Mission Request Destination_x'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_object(merge_dispatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_numerical(merge_dispatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dispatch['Pallet Number'].sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merge_dispatch.groupby(['Order Number','Pallet Number'])['Location Mission Request Destination_x'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merge_dispatch[merge_dispatch['Pallet Number']==59717008][['Location Mission Request Destination_x','Previous Value','New Value','Loadout Date','Location Room Code_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dispatch[merge_dispatch['Pallet Number']==59756595][['Location Mission Request Destination_x','Previous Value','New Value','Loadout Date','Location Room Code_y','Container','Envelope Number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dispatch[merge_dispatch['Container']==8548.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dispatch[merge_dispatch['Container']!='na'].groupby('Container Number')['Pack Type Code'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Order Structure?\n",
    "    - order with container number-> Container Vessel, order without container number  -> Chartered Vessel\n",
    "    - single order number can has several container\n",
    "    - all pallet with same envelope number will be loadout at same loadout time, except for 4 envelop number has           2 loadout date, these 4 envelopes are are being loadout together at second loadout under no container number, together with an envelope number 193023 that has 3 pallet. Make up 56 pallet in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique element in Order Number :{}'.format(len(merge_dispatch['Order Number'].unique())))\n",
    "print('Unique element in Container :{}'.format(len(merge_dispatch['Container'].unique())))\n",
    "print('Unique element in Container Number :{}'.format(len(merge_dispatch['Container Number'].unique())))\n",
    "print('Unique element in Envelope Number :{}'.format(len(merge_dispatch['Envelope Number'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merge_dispatch.groupby(['Container','Container Number','Envelope Number'])['Loadout Date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all envelope number matched with one loadut date, except 4 of them that has 2 loadout date 193024,193025,193026,193027\n",
    "merge_dispatch.groupby(['Envelope Number'])['Loadout Date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''these envelope with 2 loadout date has no container id, and all shipped out at same time, suggest it go to chartered?'''\n",
    "\n",
    "print(merge_dispatch[merge_dispatch['Envelope Number']==193024].groupby(['Container','Container Number','Envelope Number'])['Loadout Date'].value_counts())\n",
    "print('')\n",
    "print(merge_dispatch[merge_dispatch['Envelope Number']==193025].groupby(['Container','Container Number','Envelope Number'])['Loadout Date'].value_counts())\n",
    "print('')\n",
    "print(merge_dispatch[merge_dispatch['Envelope Number']==193026].groupby(['Container','Container Number','Envelope Number'])['Loadout Date'].value_counts())\n",
    "print('')\n",
    "print(merge_dispatch[merge_dispatch['Envelope Number']==193027].groupby(['Container','Container Number','Envelope Number'])['Loadout Date'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dispatch[merge_dispatch['Loadout Date']=='2019-08-02 14:45:00'].groupby(['Container','Envelope Number'])['Pallet Number'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dispatch[merge_dispatch['Envelope Number']==193023]['Loadout Date'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Envelope has been loaded out daily?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merge_dispatch.groupby(['Loadout Date','Container','Container Number'])['Envelope Number'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why there is pallet with loadout date before July 2019 although dispatched was merge to transaction data started from July 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_loadout=[193256,193189,193243,193342,197087,197157,193017,197251,197230,197268,197336,197367]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dispatch[merge_dispatch['Envelope Number'].apply(lambda x: x in old_loadout)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Cannot delete as this will reduce total pallet being move, processed ------\n",
    "# --- Only delete when analysing  data from Loadout persepctive\n",
    "\n",
    "## Delete transaction with loadout date before July 2019 and after July 2019\n",
    "\n",
    "#merge_dispatch['Loadout Date']=pd.to_datetime(merge_dispatch['Loadout Date'],format='%Y-%m-%d %H:%M:%S')\n",
    "#merge_dispatch[merge_dispatch['Loadout Date'].dt.month!=7]\n",
    "#merge_dispatch=merge_dispatch[merge_dispatch['Loadout Date'].dt.month==7]\n",
    "\n",
    "## Delete transaction with loadout date before 15 July 2019\n",
    "    - this is because currently there is no transaction data in June, transaction data of pallet that being shipped out before 15 June will has no full transaction data visibility\n",
    "    \n",
    "#merge_dispatch=merge_dispatch[merge_dispatch['Loadout Date'].dt.day>=15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Every pallet, how many transaction needed for each destination\n",
    "    - Not the same with --> How many transaction happen in each process everyday?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test=merge_dispatch.loc[merge_dispatch['Location Mission Request Destination_x']!='na'].groupby('Location Mission Request Destination_x')['Pallet Number'].value_counts()\n",
    "test=merge_dispatch.groupby('Location Mission Request Destination_x')['Pallet Number'].value_counts()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test=test.unstack(level=1).T\n",
    "f_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test[f_test['LAB'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Total Transition in each Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test.plot(kind='hist',alpha=0.3,bins=50,figsize=(16,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,36))\n",
    "for idx,dest in enumerate(f_test.columns):\n",
    "    plt.subplot(len(f_test.columns),1,idx+1)\n",
    "    f_test[dest].plot(kind='hist',alpha=0.3,bins=40)\n",
    "    plt.title(dest,fontsize=20)\n",
    "    plt.xlabel('Transition Quantity')\n",
    "    plt.ylabel('Pallet Quantity')\n",
    "    left, right = plt.xlim()\n",
    "    plt.xlim(0,right)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Mission Request Destination of transaction everyday?\n",
    "- not the same with --> How many transaction in each department everyday?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=merge_dispatch.groupby('Location Mission Request Destination_x')['Pallet Number'].resample('D').count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Location Mission Request Destination_x'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test[test['Location Mission Request Destination_x']=='RPK']\n",
    "#test[test['Location Mission Request Destination_x']=='FW']\n",
    "#test[test['Location Mission Request Destination_x']=='SPQI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_test=test.pivot(index='Transaction Date Time',columns='Location Mission Request Destination_x',values='Pallet Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_test.plot(kind='bar',stacked=True,figsize=(17,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each pallet, when is the last transaction in each Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking following result\n",
    "#merge_dispatch[merge_dispatch['Pallet Number']==53188675][['Previous Value','New Value','Loadout Date','Location Mission Request Destination_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=merge_dispatch.reset_index()\n",
    "test=test.groupby(['Pallet Number','Location Mission Request Destination_x'])['Transaction Date Time','Previous Value','New Value','Loadout Date'].last()\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each pallet, what is the first and last transaction in each Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=merge_dispatch.reset_index()\n",
    "test_first=test.groupby(['Pallet Number','Location Mission Request Destination_x'])['Transaction Date Time','Previous Value','New Value'].first()\n",
    "test_last=test.groupby(['Pallet Number','Location Mission Request Destination_x'])['Transaction Date Time','Previous Value','New Value'].last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_first.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_first=test_first.reset_index(level='Location Mission Request Destination_x',col_level=1)\n",
    "#test_last=test_last.reset_index(level='Location Mission Request Destination_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_first.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_last.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge=test_first.merge(test_last,on=test_first.index,suffixes=('_first', '_last'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each pallet, what is the duration in each process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge['Transaction_duration_per_process']=test_merge['Transaction Date Time_last']-test_merge['Transaction Date Time_first']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge['duration_per_process_sec']=test_merge['Transaction_duration_per_process'].astype('timedelta64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the distribution of duration_per_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_duration=test_merge[['key_0','duration_per_process_sec']]\n",
    "test_duration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,col in enumerate(['Pallet Number','Location Mission Request Destination_x']):\n",
    "    test_duration[col]=test_duration['key_0'].apply(lambda x:x[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_duration.drop(columns='key_0',axis='columns',inplace=True)\n",
    "test_duration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_duration['duration_per_process_sec']=test_duration['duration_per_process_sec']/(60*60*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=test_duration,x='Location Mission Request Destination_x',y='duration_per_process_sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_test_duration=pd.pivot(data=test_duration,index='Pallet Number',columns='Location Mission Request Destination_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,20))\n",
    "for idx,c in enumerate(pv_test_duration.columns):\n",
    "    plt.subplot(len(pv_test_duration.columns),1,idx+1)\n",
    "\n",
    "    pv_test_duration[c].plot(kind='box',vert=0,color='red')\n",
    "    locs, labels = plt.yticks()\n",
    "    #plt.yticks(np.arange(0, 2500000, step=500000),np.arange(0, 2.5, step=0.5))\n",
    "\n",
    "    plt.xticks()\n",
    "    plt.yticks([])\n",
    "    plt.ylabel(c[1])\n",
    "    plt.xlabel('Duration (days)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the transaction history of the pallet sorted according to pallet number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pallet=merge_dispatch['Pallet Number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pallet.last('M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the last position of each pallet in transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test=merge_dispatch.reset_index()\n",
    "test=test.groupby('Pallet Number')['Transaction Date Time','Previous Value','New Value','Loadout Date'].last()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[53188620]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dispatch.loc[merge_dispatch['Pallet Number']==53191163,['Pallet Number','Location Mission Request Destination_x','Previous Value','New Value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=merge_dispatch.reset_index()\n",
    "test=test.groupby(['Transaction Date Time','Previous Value','Pallet Number'])['Pallet Number'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.unstack(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dispatch['Previous Value'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_position=pd.DataFrame(data=merge_dispatch['Previous Value'].unique(),columns=['Position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_position['Position'].apply(lambda c:c.split('-')[2] if '-' in c else c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
