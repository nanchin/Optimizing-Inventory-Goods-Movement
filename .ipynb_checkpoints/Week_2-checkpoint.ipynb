{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content:\n",
    "    1) Import library\n",
    "    2) Configuration\n",
    "    3) Define Functions\n",
    "    4) Basic Checks\n",
    "    5) Export Data Description\n",
    "    6) Data Cleaning\n",
    "        6.1) Drop columns\n",
    "            6.1.1) Drop empty columns\n",
    "            6.1.2) Drop unilabel/univalue columns\n",
    "        6.2) Transaction\n",
    "            6.2) Fix Data Quality Issue in 'Fruit Size Code' \n",
    "        6.3) Dispatched\n",
    "    7) Convert to Time Series Data\n",
    "        7.1) Transaction\n",
    "            7.1.1) Drop duplicated transactions\n",
    "        7.2) Dispatched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "from scipy.stats import skew,kurtosis\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# to view all columns\n",
    "pd.set_option('display.max_columns',500)\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_1='C:/Users/Nan/Documents/GitHub_Data/TransactionDetails.csv'\n",
    "filepath_2='C:/Users/Nan/Documents/GitHub_Data/Dispatched.csv'\n",
    "filename_1=filepath_1.rstrip('.csv')\n",
    "filename_2=filepath_2.rstrip('.csv')\n",
    "transaction=pd.read_csv(filepath_1)\n",
    "dispatched=pd.read_csv(filepath_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datatype(arg_df):\n",
    "    \n",
    "    col_bool=[]\n",
    "    col_object=[]\n",
    "    col_number=[]\n",
    "    col_catogory=[]\n",
    "    \n",
    "    for col in arg_df.columns:\n",
    "        datatype=arg_df[col].dtypes\n",
    "        if datatype==bool:\n",
    "            col_bool.append(col)\n",
    "        elif datatype==object :\n",
    "            col_object.append(col)\n",
    "        elif str(datatype)=='category':\n",
    "            col_catogory.append(col)\n",
    "        else:\n",
    "            col_number.append(col)\n",
    "    print('This dataset has {} Columns\\nbool\\t:{} \\nobject\\t:{}  \\ncategory:{} \\nnumeric\\t:{} '\n",
    "          .format(len(arg_df.columns),len(col_bool),len(col_object),len(col_catogory),len(col_number)))\n",
    "    \n",
    "    del arg_df\n",
    "    gc.collect()\n",
    "    \n",
    "    return col_bool,col_object,col_catogory,col_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_object(arg_df):\n",
    "    \n",
    "    object_list=[]\n",
    "    category_list=[]\n",
    "    bool_list=[]\n",
    "    unilabel_list=[]\n",
    "    missing_list=[]\n",
    "    \n",
    "    for c in arg_df.columns:\n",
    "        if arg_df[c].dtypes==object:\n",
    "            object_list.append(c)\n",
    "        elif str(arg_df[c].dtypes)=='category':\n",
    "            category_list.append(c)\n",
    "        elif arg_df[c].dtypes==bool:\n",
    "            bool_list.append(c)\n",
    "    if len(object_list)+len(category_list)+len(bool_list)>0:    \n",
    "        index_list=['Count','Unique','Missing (%)','Top','Top (%)','Bottom','Bottom (%)']\n",
    "        df_summary=pd.DataFrame(data=np.zeros((len(index_list),len(object_list))),index=index_list,columns=object_list)\n",
    "\n",
    "        for col in object_list+category_list+bool_list:\n",
    "            vc=arg_df[col].value_counts().reset_index()\n",
    "            df_summary.loc['Count',col]=(arg_df[col].count())\n",
    "            df_summary.loc['Unique',col]=len(arg_df[col].unique())\n",
    "            df_summary.loc['Missing (%)',col]=arg_df[col].isna().mean()*100\n",
    "            df_summary.loc['Top',col]=vc.iloc[0,0]\n",
    "            df_summary.loc['Top (%)',col]=vc.iloc[0,1]/len(arg_df)*100\n",
    "            if len(arg_df[col].unique())>1:\n",
    "                df_summary.loc['Bottom',col]=vc.iloc[-1,0]\n",
    "                df_summary.loc['Bottom (%)',col]=vc.iloc[-1,1]/len(arg_df)*100\n",
    "            else:\n",
    "                unilabel_list.append(col)\n",
    "            if df_summary.loc['Missing (%)',col]==100:\n",
    "                missing_list.append(col)\n",
    "                \n",
    "        df_summary=df_summary.T.sort_values(['Missing (%)','Unique'],ascending=False)\n",
    "        df_summary=df_summary[(df_summary['Unique']>1) & (df_summary['Missing (%)']!=100)]\n",
    "        df_summary.reset_index(inplace=True)\n",
    "        df_summary.index=df_summary.index+1\n",
    "        df_summary.columns=['Attribute']+index_list\n",
    "        \n",
    "        print('SUMMARY OF {} NON-NUMERICAL ATTRIBUTES:\\n'.format(\n",
    "            len(object_list)+len(category_list)+len(bool_list)))\n",
    "        if len(object_list)>0:\n",
    "            print('{} Object Columns'.format(len(object_list)))\n",
    "        if len(category_list)>0:\n",
    "            print('{} Categorical Columns'.format(len(category_list)))\n",
    "        if len(bool_list)>0:\n",
    "            print('{} Bool Columns'.format(len(bool_list)))\n",
    "        if len(unilabel_list)>0:\n",
    "            print('\\n{} Columns with Single Label : \\n{}'.format(len(unilabel_list),unilabel_list))\n",
    "        if len(missing_list)>0:\n",
    "            print('\\n{} Empty Columns: \\n{}'.format(len(missing_list),missing_list))   \n",
    "            \n",
    "        del arg_df,object_list,vc,index_list,unilabel_list,missing_list\n",
    "        gc.collect()\n",
    "        return df_summary\n",
    "    else:\n",
    "        print('No Non-Numerical Attributes')\n",
    "        \n",
    "def summary_numerical(arg_df):\n",
    "\n",
    "    target_list=[]\n",
    "    missing_list=[]\n",
    "    zero_skew_list=[]\n",
    "    \n",
    "    for c in arg_df.columns:\n",
    "        datatype=arg_df[c].dtypes\n",
    "        if datatype != object and datatype != bool and str(datatype) != 'category':\n",
    "            target_list.append(c)\n",
    "    if len(target_list)>0:\n",
    "        from scipy.stats import skew,kurtosis\n",
    "        \n",
    "        index_list=['Count','Missing (%)','Mean','Median','Min','Max','Skewness','Kurtosis']\n",
    "        df_summary=pd.DataFrame(data=np.zeros((len(index_list),len(target_list))),\n",
    "                                index=index_list,columns=target_list)\n",
    "        for col in target_list:\n",
    "            df_summary.loc['Count',col]=arg_df[col].count()\n",
    "            df_summary.loc['Missing (%)',col]=arg_df[col].isna().mean()*100\n",
    "            if df_summary.loc['Missing (%)',col]!=100:\n",
    "                df_summary.loc['Mean',col]=arg_df[col].mean()\n",
    "                df_summary.loc['Median',col]=arg_df[col].median()\n",
    "                df_summary.loc['Min',col]=arg_df[col].min()\n",
    "                df_summary.loc['Max',col]=arg_df[col].max()\n",
    "                df_summary.loc['Skewness',col]=skew(arg_df[col])\n",
    "                if df_summary.loc['Skewness',col]==0:\n",
    "                    zero_skew_list.append(col)\n",
    "                df_summary.loc['Kurtosis',col]=kurtosis(arg_df[col])\n",
    "            else:\n",
    "                missing_list.append(col)\n",
    "                \n",
    "        df_summary=df_summary.T.sort_values(['Missing (%)','Skewness'],ascending=False)\n",
    "        df_summary=df_summary[(df_summary['Skewness']!=0) & (df_summary['Missing (%)']!=100)]\n",
    "        df_summary.reset_index(inplace=True)\n",
    "        df_summary.index=df_summary.index+1\n",
    "        df_summary.columns=['Attribute']+index_list\n",
    "        \n",
    "        print('SUMMARY OF {} NUMERICAL ATTRIBUTES:'.format(len(target_list)))\n",
    "        if len(zero_skew_list)>0:\n",
    "            print('\\n{} Columns with Single Value: \\n{}'.format(len(zero_skew_list),zero_skew_list))\n",
    "        if len(missing_list)>0:\n",
    "            print('\\n{} Empty Columns: \\n{}'.format(len(missing_list),missing_list))\n",
    "        del arg_df,target_list,index_list\n",
    "        gc.collect()\n",
    "\n",
    "        return df_summary\n",
    "    else:\n",
    "        print('No Numerical Attributes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_Data_Description(arg_df,**kwarg):\n",
    "    from scipy.stats import skew\n",
    "    data_description=pd.DataFrame()\n",
    "    for c in arg_df.columns:\n",
    "        data_description.loc[c,'Datatype']=arg_df[c].dtypes\n",
    "        data_description.loc[c,'Missing%']='{:.3f}'.format((len(arg_df[c])-arg_df[c].count())/len(arg_df[c])*100)\n",
    "        if (len(arg_df[c])-arg_df[c].count())/len(arg_df[c])*100!=100:\n",
    "            if arg_df[c].dtypes==object:\n",
    "                data_description.loc[c,'Unique']=len(arg_df[c].unique())\n",
    "                if len(arg_df[c].unique())==1:\n",
    "                    data_description.loc[c,'Remark']='Dropped because this column has only single lable'\n",
    "                else:\n",
    "                    data_description.loc[c,'Remark']='Frequent: {} ({:.3f} %)'.format(\n",
    "                        arg_df[c].mode()[0],arg_df[arg_df[c]==arg_df[c].mode()[0]][c].count()/len(arg_df[c])*100)\n",
    "            else:\n",
    "                if skew(arg_df[c])==0:\n",
    "                    data_description.loc[c,'Unique']=1\n",
    "                    data_description.loc[c,'Remark']='Dropped because this column has only single value'\n",
    "                else:\n",
    "                    data_description.loc[c,'Remark']='MAX: {:.3f} MIN: {:.3f} MEAN: {:.3f} STD: {:.3f}'.format(\n",
    "                        arg_df[c].max(),arg_df[c].min(),arg_df[c].mean(),arg_df[c].std())\n",
    "        else:\n",
    "            data_description.loc[c,'Remark']='Dropped because this column is empty'\n",
    "    data_description.reset_index(inplace=True)\n",
    "    data_description.index=data_description.index+1\n",
    "    data_description=data_description.rename(columns={'index':'Attribute'})\n",
    "    if ('surfix' in kwarg):\n",
    "        data_description.to_excel('data_description_{}.xlsx'.format(kwarg['surfix']))\n",
    "    else:\n",
    "        import datetime\n",
    "        currentDT = datetime.datetime.now()\n",
    "        time=str(currentDT.year)+'-'+str(currentDT.month)+'-'+str(currentDT.day)+' '+str(currentDT.hour)+str(currentDT.minute)+str(currentDT.second)\n",
    "        data_description.to_excel('data_description_{}.xlsx'.format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectify_to_category(arg_df,actual_col_list):\n",
    "    \n",
    "    object_list=[]\n",
    "    '''\n",
    "    for c in arg_df.columns:\n",
    "        if arg_df[c].dtypes==object or str(arg_df[c].dtypes)=='category':\n",
    "            object_list.append(c)\n",
    "    if len(object_list)>0: \n",
    "        for column in [c for c in object_list if c not in actual_col_list]: '''\n",
    "    for c in arg_df.columns:\n",
    "        if arg_df[c].dtype!=bool:\n",
    "            object_list.append(c)\n",
    "    if len(object_list)>0:\n",
    "        for columns in [c for c in object_list if c not in actual_col_list]:\n",
    "            arg_df[columns]=arg_df[columns].astype('category',inplace=True)\n",
    "        print('Change Datatype of {} Column to Category : \\n{}'.format(len(object_list),object_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unilable_column(arg_df):\n",
    "    \n",
    "    target_list=[]\n",
    "    object_list=[]\n",
    "    number_list=[]\n",
    "    for c in arg_df.columns:\n",
    "        if (arg_df[c].dtypes==object) | (str(arg_df[c].dtypes)=='category') | (arg_df[c].dtypes==bool):\n",
    "            object_list.append(c)\n",
    "        else:\n",
    "            number_list.append(c)\n",
    "    if len(object_list)>0:    \n",
    "        for c in object_list:\n",
    "            if len(arg_df[c].unique())==1:\n",
    "                target_list.append(c)\n",
    "    \n",
    "    if len(number_list)>0:   \n",
    "        from scipy.stats import skew\n",
    "        for c in number_list:\n",
    "            if skew(arg_df[c])==0:\n",
    "                target_list.append(c)\n",
    "                \n",
    "    if len(target_list)>0:\n",
    "        arg_df.drop(columns=target_list,axis='columns',inplace=True)\n",
    "        print('Drop {} Columns with Single Label:\\n{}'.format(len(target_list),target_list))\n",
    "    else: \n",
    "        print('No Columns with Single Label/Value')\n",
    "\n",
    "    del target_list,object_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empty_column(arg_df):\n",
    "    target_list=[]\n",
    "    for c in arg_df.columns:\n",
    "        if arg_df[c].count()==0:\n",
    "            target_list.append(c)\n",
    "    if len(target_list)>0:\n",
    "        arg_df.drop(columns=target_list,axis=1,inplace=True)\n",
    "        print('Delete {} Empty Column : \\n{}'.format(len(target_list),target_list))\n",
    "    else:\n",
    "        print('No Empty Column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_description(arg_df,str_1,str_2):\n",
    "    arg_df.groupby(str_1)[str_2].value_counts(dropna=False,\n",
    "                                              ascending=False).to_frame().to_csv('{}.csv'.format(str_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Basic Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1) Dataset -Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_list,object_list,cat_list,num_list=get_datatype(transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_object(transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_numerical(transaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2) Dataset - Dispatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_list,object_list,cat_list,num_list=get_datatype(dispatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_object(dispatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_numerical(dispatched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Export Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export_Data_Description(transaction,surfix='transaction')\n",
    "#export_Data_Description(dispatched,surfix='dispatched')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1) Drop columns\n",
    "    6.1.1) Drop empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_empty_column(transaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    6.1.2) Drop unilabel/univalue columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_unilable_column(transaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    6.1.3) Drop Column 'Transfer To Coolstore' and 'Transfer To Supplier' with 99% data missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction['Transfer To Coolstore'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.drop(columns='Transfer To Coolstore',axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.drop(columns='Transfer To Supplier',axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2) Dataset -Transaction\n",
    "    6.2.1) Fix Data Quality Issue in 'Fruit Size Code' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(transaction['Fruit Size Code'].unique()))\n",
    "transaction['Fruit Size Code'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction['Fruit Size Code']=transaction['Fruit Size Code'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(transaction['Fruit Size Code'].unique()))\n",
    "transaction['Fruit Size Code'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3) Dataset - Dispatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_empty_column(dispatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_unilable_column(dispatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.drop(columns='Last Ppqi Date',axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export and delete Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code=['Location Room Code','Storage Source Code','Pack Label Code','Pack Indicator Code','Clearance Protocol Code',\n",
    "     'Customer Label Code','Dry Matter Code','Quality Inspection Indicator Code','Japan Sub Brand Code',\n",
    "     'Trial Packing Indicator Code','Marketer Code','Brand Code','Variety Code','Fruit Size Code',\n",
    "      'Pack Category Code','Purchase Pool Code','Maturity Indicator Code','Plant Code']\n",
    "\n",
    "descrip=[x.replace('Code','Description') for x in code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c,d in zip(code,descrip):\n",
    "#    export_description(dispatched,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.drop(columns=descrip,axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export_description(dispatched,'Packhouse Code','Zespri Li Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dispatched.groupby(['Doi Number','Doi Clearance Date'])['Australian Inspection Reference'].value_counts().to_frame().to_csv('DOI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.drop(columns=['Doi Clearance Date','Australian Inspection Reference','Zespri Li Number'],axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Pallet Note Type and Pallet Note Test , drop them\n",
    "- as both are referring to damaged pallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched['Pallet Note']=dispatched['Pallet Note Type'].notnull() & dispatched['Pallet Note Text'].notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.drop(columns=['Pallet Note Type','Pallet Note Text'],axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop 'OKUntil ISODate' because it is duplicate of 'Ok Until Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.drop(columns='OKUntil ISODate',axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Days difference between Loadout Date and other Date Attribute in dispatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_attribute=[c for c in dispatched.columns if 'Date' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in date_attribute:\n",
    "    dispatched[c]=pd.to_datetime(dispatched[c],format='%d/%m/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_attribute.remove('Loadout Date')\n",
    "new_date_attribute=[c.replace(' ','_') for c in date_attribute]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,c in enumerate(date_attribute):\n",
    "    if (c !='Load Start Date'):\n",
    "        dispatched[new_date_attribute[idx]+'_day']=dispatched[c]-dispatched['Loadout Date']\n",
    "        dispatched[new_date_attribute[idx]+'_day']=dispatched[new_date_attribute[idx]+'_day'].astype('timedelta64[D]')\n",
    "    else:\n",
    "        dispatched[new_date_attribute[idx]+'_hour']=dispatched['Loadout Date']-dispatched[c]\n",
    "        dispatched[new_date_attribute[idx]+'_hour']=dispatched[new_date_attribute[idx]+'_hour'].astype('timedelta64[h]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.drop(columns=date_attribute,axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched['Load_Start_Date_hour']=-dispatched['Load_Start_Date_hour']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Convert to Time Series Data\n",
    "Some of the attributes in this dataset contain datetime information,i.e. \n",
    "- Ok Until Date\n",
    "- Pack Date\n",
    "- Transaction Date\n",
    "- Transaction Date Time\n",
    "\n",
    "Since the focus of this project is on pallet transaction, this dataset will be converted into time series data based on Transaction Date Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction['Transaction Date Time']=pd.to_datetime(transaction['Transaction Date Time'],format='%d/%m/%Y %I:%M:%S %p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_ori=transaction.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction=transaction.set_index(keys='Transaction Date Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1) Transaction\n",
    "    7.1.1) Drop duplicated transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_drop_duplicate=transaction.shape\n",
    "transaction.drop_duplicates(inplace=True)\n",
    "print('Total number of transaction before dropping duplicate : {}'.format(before_drop_duplicate[0]))\n",
    "print('Total number of transaction after dropping duplicate : {}'.format(transaction.shape[0]))\n",
    "print('Total number of transaction decrease by {:.2f} %'.format(\n",
    "    (before_drop_duplicate[0]-transaction.shape[0])/before_drop_duplicate[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_drop_duplicate2=dispatched.shape\n",
    "dispatched.drop_duplicates(inplace=True)\n",
    "print('Total number of instances in Dispatched before dropping duplicate : {}'.format(before_drop_duplicate2[0]))\n",
    "print('Total number of instances in Dispatched after dropping duplicate : {}'.format(dispatched.shape[0]))\n",
    "print('Total number of instances in Dispatched decrease by {:.2f} %'.format(\n",
    "    (before_drop_duplicate2[0]-dispatched.shape[0])/before_drop_duplicate2[0]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    7.1.2) Drop row with 'Value Type'= NaN, then drop column 'Value Type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction['Value Type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction[transaction['Value Type'].isna()]['New Value'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction[transaction['Value Type'].isna()]['Previous Value'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transaction[transaction['Value Type'].isna()][['Pallet Number','Location Mission Request Destination','Room']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transaction[transaction['Pallet Number']==57430039][['Pallet Number','Previous Value','New Value','Username','Value Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction[transaction['Pallet Number']==56996581][['Previous Value','New Value','Value Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction['drop_value_type']=(transaction['Value Type'].isna()) & (transaction['New Value'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction=transaction[transaction['drop_value_type']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_time=transaction[transaction['Value Type'].isna()]['Transaction Date']\n",
    "t_pallet=transaction[transaction['Value Type'].isna()]['Pallet Number']\n",
    "t_value=transaction[transaction['Value Type'].isna()]['New Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t,p,v in zip(t_time,t_pallet,t_value):\n",
    "    transaction.loc[(transaction['Pallet Number']==p) & (transaction['Transaction Date']==t),'New Value']=t_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_ori=transaction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction=transaction[transaction['Value Type'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.drop(['Value Type','drop_value_type'],axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This section delete {} row, the shape currently is {}.'.format(shape_ori[0]-transaction.shape[0],transaction.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    7.1.2) Drop row with 'Value Type'= NaN, then drop column 'Value Type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.groupby('Pallet Number')['Username'].count().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction[transaction.duplicated(subset=['Pallet Number','Transaction Date'])]['Pallet Number'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transaction[transaction['Pallet Number']==59434813][['Previous Value','New Value','Location Mission Request Destination','Username']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_ori=transaction.shape\n",
    "transaction.drop_duplicates(subset=['Pallet Number','Transaction Date'],keep='last',inplace=True)\n",
    "print('This section delete {} row, the shape currently is {}.'.format(shape_ori[0]-transaction.shape[0],transaction.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    7.1.3) Replace Missing Data in Previous Value with UNKNOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transaction[transaction['Previous Value'].isna()]['Pallet Number'].value_counts().head()\n",
    "#transaction[transaction['Pallet Number']==60919422][['Previous Value','New Value']]\n",
    "transaction.loc[transaction['Previous Value'].isna(),'Previous Value']='UNKNOWN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2) Dispatched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the attributes in this dataset contain datetime information,i.e.\n",
    "\n",
    "    - Ok Until Date\n",
    "    - Pack Date\n",
    "    - Loadout Date\n",
    "    - Load Start Date\n",
    "\n",
    "Since the focus of this project is on loadout bay, this dataset will be converted into time series data based on Loadout Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched['Loadout Date']=pd.to_datetime(dispatched['Loadout Date'],format='%d/%m/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.sort_values(by=['Loadout Date','Order Number','Envelope Number'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched_ori=dispatched.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.set_index(keys='Loadout Date',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Daily_Transaction=transaction['Pallet Number'].resample('D').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "axes=fig.add_axes([0,0,6,4])\n",
    "Daily_Transaction.plot(marker='o',ax=axes,fontsize=50,markersize=25)\n",
    "axes.set_title('Daily Pallet Transaction',fontsize=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive Attribute - Shift, Shift_Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction['Day_Shift']=(transaction.index.hour>=7) & (transaction.index.hour<19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction['Shift_Hour']=transaction.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction['Shift_Date']=transaction.index.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction['Shift_Date']=pd.to_datetime(transaction['Shift_Date'],format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle shift date of night shift with transaction time over 12am\n",
    "transaction.loc[transaction['Shift_Hour']<7,'Shift_Date']=transaction.loc[transaction['Shift_Hour']<7,'Shift_Date']+datetime.timedelta(days=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.loc[:,'Shift_Date'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Daily Shift Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_shift_transaction=transaction.groupby(['Shift_Date','Day_Shift'])['Pallet Number'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_shift_transaction['Day_Shift']=daily_shift_transaction['Day_Shift'].map({True:'Dayshift',False:'Nightshift'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_daily_shift_transaction=pd.pivot(data=daily_shift_transaction,index='Shift_Date',columns='Day_Shift',values='Pallet Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_daily_shift_transaction['Allshift']=pv_daily_shift_transaction.sum(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_daily_shift_transaction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(pv_daily_shift_transaction['Dayshift'],label='Dayshift',marker='o',color='blue')\n",
    "plt.plot(pv_daily_shift_transaction['Nightshift'],label='Nightshift',marker='X',markersize=10,color='black')\n",
    "pv_daily_shift_transaction['Allshift'].plot.area(alpha=0.3,color='skyblue')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Transaction')\n",
    "plt.title('Daily Shift Transaction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction['Shift_Date']=transaction['Shift_Date'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Distribution of Total Transactions per Pallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_transaction_pallet=pd.pivot_table(data=transaction,index='Pallet Number'\n",
    "                                        ,columns='Username',values='Transaction Date'\n",
    "                                       ,aggfunc='count').sum(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_transaction_pallet.sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "total_transaction_pallet.plot.hist(bins=40,title='Distribution of Total Transactions per Pallet',alpha=0.6)\n",
    "plt.xlabel('Transactions per Pallet')\n",
    "plt.xlim([0,80])\n",
    "\n",
    "plt.twinx()\n",
    "total_transaction_pallet.plot.hist(bins=40,title='Distribution of Total Transactions per Pallet',cumulative=True,color='red',alpha=0.3,normed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15,6))\n",
    "axes=fig.add_axes([0,0,6,4])\n",
    "transaction['New Value'].value_counts(dropna=False)[:15].plot(kind='bar',ax=axes,fontsize=60)\n",
    "axes.set_title('Pallet New Location',fontsize=80)\n",
    "axes.set_xlabel('New Location',fontsize=80)\n",
    "axes.set_ylabel('Transaction',fontsize=80)\n",
    "axes.set_ylim([0,7000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['New Value']=='CONTR'\n",
    "t_CONTR=transaction.loc[transaction['New Value']=='CONTR',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "t_CONTR.groupby(t_CONTR.index.day)['Pallet Number'].count().plot(kind='bar')\n",
    "plt.ylabel('Transaction with New Value = CONTR')\n",
    "plt.title('Daily Transaction with New Value = CONTR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Request Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No Relationship between Room and Location Mission Request Destination\n",
    "# Room = Location Room Code-Location Row Code-Location Column-Location Height\n",
    "transaction[transaction['Location Mission Request Destination']=='SPQI'][['Room','Location Room Code','Location Row Code','Location Column','Location Height','Location Request Number',\n",
    " 'Location Mission Request Destination']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction['Location Request Number'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total pallet associate with this rqt number is 20, is it possible request number is linked to specified order number?\n",
    "transaction[transaction['Location Request Number']==1815]['Pallet Number'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rqt_number_destination=transaction.groupby('Location Mission Request Destination')['Location Request Number'].value_counts().unstack()\n",
    "rqt_number_destination=rqt_number_destination.T\n",
    "rqt_number_destination['Total Transaction']=rqt_number_destination.sum(axis='columns')\n",
    "rqt_number_destination.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sns.lineplot(x=rqt_number_destination.index,y='Total Transaction',data=rqt_number_destination,ax=axes[0])\n",
    "sns.boxplot(y='Total Transaction',data=rqt_number_destination,ax=axes[1])\n",
    "plt.ylim([0,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upon checking, request number with exceptional high transaction are likely valid because there are hundreds of pallet linked to these request number\n",
    "rqt_number_destination.sort_values(by='Total Transaction',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transaction[transaction['Location Request Number']==1388]['Pallet Number'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Total Transactions of each Mission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_transc_destination=transaction.pivot_table(index='Location Request Number',columns='Location Mission Request Destination',\n",
    "                        values='Pallet Number',aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=['skyblue','cyan','red','green','blue','orange','violet','grey','olive']\n",
    "\n",
    "f, axes=plt.subplots(1, len(total_transc_destination.columns), figsize=(16, 4))\n",
    "\n",
    "for ind,c in enumerate(total_transc_destination.columns):\n",
    "    #plt.figure(figsize=(16, 4))\n",
    "    plt.subplot(1,len(total_transc_destination.columns),ind+1)\n",
    "    total_transc_destination[total_transc_destination[c].notnull()][c].plot.box(color=colors[ind],\n",
    "                                                                                title='Total:{}'.\n",
    "                                                                                format(total_transc_destination[total_transc_destination[c]>0][c].sum()))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is only single line in DA1 because there is only one request number attached to DA1\n",
    "total_transc_destination[total_transc_destination['DA1'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_object(transaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location ended with symbol '---' in Previous Value and Room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_p_value=transaction['Previous Value'].value_counts().sort_values(ascending=False)\n",
    "t_n_value=transaction['New Value'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_p_value=t_p_value.to_frame()\n",
    "t_n_value=t_n_value.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_p_value.reset_index(inplace=True)\n",
    "t_n_value.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left=t_p_value,right=t_n_value,left_on=t_p_value.index,right_on=t_n_value.index).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del t_p_value,t_n_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction['Previous Value']=transaction['Previous Value'].apply(lambda x:str(x).split('---')[0] if '---' in str(x) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Missing Data in Location Row Code, Column and Height with na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location Row Code and Column are NaN because Location Room Code is UNKNOWN\n",
    "# the other reason these data is NaN because the Room Code is FW.CONTR etc.\n",
    "# transaction[['Pallet Number','Location Room Code','Location Column','Location Row Code','Location Height']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.loc[transaction['Location Row Code'].isna(),'Location Row Code']='na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.loc[transaction['Location Column'].isna(),'Location Column']='na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.loc[transaction['Location Height'].isna(),'Location Height']='na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transaction[transaction['Location Height'].isna()][['Location Room Code','Location Row Code',\n",
    "                                                    'Location Column','Location Height']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Doi Number with True/ False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction['DOI_Number']=transaction['Doi Number'].notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.drop(columns='Doi Number',axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Data with Missing Request Destination with 'na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.loc[transaction['Location Mission Request Destination'].isna(),'Location Mission Request Destination']='na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction['Location Mission Request Destination'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data in Location Room Code with UNKNOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction[transaction['Location Room Code'].isna()][['Room','Location Room Code',\n",
    "                                                       'Location Column','Location Row Code',\n",
    "                                                       'Previous Value','New Value']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction[transaction['Location Room Code']=='UNKNOWN'][['Room','Location Room Code',\n",
    "                                                       'Location Column','Location Row Code',\n",
    "                                                       'Previous Value','New Value']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.loc[transaction['Location Room Code'].isna(),'Location Room Code']='UNKNOWN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle '---' in transaction['Room']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction['Room'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.loc[transaction['Room']=='---','Room']='UNKNOWN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction['Room']=transaction['Room'].apply(lambda x : str(x).split('---')[0] if  '---' in x else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =========No more missing data in transactional dataset========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_object(dispatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_numerical(dispatched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Missing data in Row Code & Column with na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[['Location Room Code','Location Row Code','Location Column','Location Height','Location Request Number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dispatched[dispatched['Location Row Code'].isna()]['Location Room Code'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.loc[dispatched['Location Row Code'].isna(),['Location Row Code','Location Column','Location Height']]='na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.loc[dispatched['Location Room Code'].isna(),'Location Room Code']='UNKNOWN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace missing data in 'Container' and 'Container Number' with na, represent chartered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.loc[dispatched['Container'].isna(),'Shipment Type Code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.loc[dispatched['Container'].notnull(),'Shipment Type Code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.loc[dispatched['Container'].isna(),['Container','Container Number']]='na'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace missing data in 'Location Request Number' and 'Location Mission Request Destination' with na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched[dispatched['Location Request Number'].isna()]['Location Mission Request Destination'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.loc[dispatched['Location Request Number'].isna(),['Location Request Number','Location Mission Request Destination']]='na'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace missing data in Repack_Date_day,Tkl_Email_Date_day,Last_Spqi_Date_day with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.loc[dispatched['Repack_Date_day'].isna(),'Repack_Date_day']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched.loc[dispatched['Tkl_Email_Date_day'].isna(),'Tkl_Email_Date_day']=0\n",
    "dispatched.loc[dispatched['Last_Spqi_Date_day'].isna(),'Last_Spqi_Date_day']=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dispatched : filter out subset of important attribure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched_short=['Pallet Number',\n",
    "'Location Room Code', 'Location Row Code','Location Column', 'Location Height',\n",
    "'Loadout Priority',\n",
    "'Purchase Pool Code',\n",
    "'Pack Code','Pack Type Code', 'Stacking Configuration Code',\n",
    "'Order Number', 'Order Line Number','Envelope Number',\n",
    "'Container', 'Container Number',\n",
    "'Shipment Type Code', 'Destination Port Code', 'Trucking Company Code',\n",
    "'Location Request Number','Location Mission Request Destination','Pallet Note',\n",
    " 'Repack_Date_day',\n",
    " 'Last_Spqi_Date_day',\n",
    " 'Pack_Date_day',\n",
    " 'Ok_Until_Date_day',\n",
    " 'Load_Start_Date_hour',\n",
    " 'Tkl_Email_Date_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched_s=dispatched[dispatched_short]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_numerical(dispatched_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched_s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge transaction with dispatched_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched_s.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dispatch=transaction.merge(dispatched_s,on='Pallet Number')\n",
    "merge=transaction.merge(dispatched_s,on='Pallet Number',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dispatch.to_csv('merge_dispatch.csv',index=False)\n",
    "merge.to_csv('merge.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merge_dispatch_only['Pallet Number'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dispatch['Location Mission Request Destination_x'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_object(transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "daily_loadout=dispatched[['Pallet Number']].resample('D').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_loadout_july=daily_loadout.loc['July 2019',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_loadout_july.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in dispatched.columns if 'Date' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(daily_loadout_july['Pallet Number'],marker='o',markerfacecolor='r')\n",
    "plt.title('Daily Loadout in July 2019',fontsize=20)\n",
    "plt.ylabel('Pallet Quantity')\n",
    "x_tick_value=daily_loadout['July 2019'].index.tolist()\n",
    "x_tick_label=daily_loadout['July 2019'].index.date.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "dispatched['Location Room Code'].value_counts(normalize=False,dropna=False).head(10).plot(kind='bar')\n",
    "plt.xlabel('Location Room Code')\n",
    "plt.ylabel('Transaction')\n",
    "plt.title('Top 10 Location Room Code of Dispatched Pallet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_loadout['July 2019'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pallet in Both Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pallet_in_transaction=transaction['Pallet Number'].unique()\n",
    "len(pallet_in_transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pallet_in_dispatched=dispatched['Pallet Number'].unique()\n",
    "len(pallet_in_dispatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pallet_in_both=[c for c in pallet_in_dispatched if c in pallet_in_transaction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pallet_in_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction['Location Height'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
